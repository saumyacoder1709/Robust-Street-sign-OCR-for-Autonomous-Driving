import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import easyocr
from ultralytics import YOLO

# Page config
st.set_page_config(
    page_title="üöó Street Sign OCR - AI for Autonomous Driving",
    page_icon="üö¶",
    layout="wide"
)

st.markdown("""
<style>
.main-header {
    font-size: 3rem;
    color: #1E88E5;
    text-align: center;
    margin-bottom: 2rem;
    font-weight: bold;
}
.metric-container {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 1rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin: 0.5rem 0;
}
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_models():
    """Load YOLO and OCR models"""
    with st.spinner("ü§ñ Loading AI models... This may take 1-2 minutes on first run."):
        try:
            # Load YOLO model
            detector = YOLO('yolov8n.pt')
            st.success("‚úÖ YOLO model loaded!")
            
            # Load OCR model (CPU only for Streamlit Cloud)
            ocr_reader = easyocr.Reader(['en', 'de'], gpu=False)
            st.success("‚úÖ OCR model loaded!")
            
            return detector, ocr_reader
            
        except Exception as e:
            st.error(f"‚ùå Error loading models: {str(e)}")
            st.error("Please try refreshing the page or contact support.")
            return None, None

def preprocess_for_ocr(image):
    """Enhanced preprocessing for better OCR (without cv2)"""
    try:
        # Convert PIL to numpy if needed
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        # Ensure proper format
        if image.dtype == np.float32:
            image = (image * 255).astype(np.uint8)
        
        # Simple resize for small images
        height, width = image.shape[:2] if len(image.shape) > 2 else image.shape
        if height < 100 or width < 100:
            scale = max(150/height, 150/width)
            new_height = int(height * scale)
            new_width = int(width * scale)
            # Use PIL for resizing instead of cv2
            if len(image.shape) == 3:
                img_pil = Image.fromarray(image)
            else:
                img_pil = Image.fromarray(image, mode='L')
            img_resized = img_pil.resize((new_width, new_height), Image.Resampling.LANCZOS)
            image = np.array(img_resized)
        
        return image
        
    except Exception:
        return image

def process_uploaded_image(uploaded_file, detector, ocr_reader, confidence_threshold):
    """Process uploaded image through AI pipeline"""
    results = {'detections': [], 'processing_time': 0}
    
    try:
        import time
        start_time = time.time()
        
        # Load image
        image = Image.open(uploaded_file)
        image_np = np.array(image)
        
        # YOLO detection
        detection_results = detector(image_np, conf=confidence_threshold)
        
        # Process each detection
        for result in detection_results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # Extract box coordinates
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = float(box.conf[0])
                    
                    # Extract ROI for OCR
                    roi = image_np[y1:y2, x1:x2]
                    
                    # Perform OCR
                    ocr_results = []
                    if roi.size > 0:
                        try:
                            # Preprocess ROI
                            processed_roi = preprocess_for_ocr(roi)
                            
                            # Run OCR on both original and processed ROI
                            raw_ocr = ocr_reader.readtext(roi, paragraph=False)
                            processed_ocr = ocr_reader.readtext(processed_roi, paragraph=False)
                            
                            # Combine and filter results
                            all_ocr = raw_ocr + processed_ocr
                            seen_texts = set()
                            
                            for (bbox, text, conf) in all_ocr:
                                clean_text = text.strip()
                                if conf > 0.3 and clean_text and clean_text not in seen_texts:
                                    ocr_results.append({
                                        'text': clean_text,
                                        'confidence': float(conf)
                                    })
                                    seen_texts.add(clean_text)
                            
                            # Sort by confidence
                            ocr_results.sort(key=lambda x: x['confidence'], reverse=True)
                            
                        except Exception as ocr_error:
                            st.warning(f"OCR processing issue: {str(ocr_error)}")
                    
                    results['detections'].append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': float(confidence),
                        'ocr_results': ocr_results
                    })
        
        results['processing_time'] = time.time() - start_time
        
    except Exception as e:
        st.error(f"Processing error: {str(e)}")
    
    return results

def create_visualization(image, results):
    """Create detection visualization with matplotlib"""
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    
    # Display image
    ax.imshow(image)
    
    # Color scheme for bounding boxes
    colors = ['#FF4444', '#44FF44', '#4444FF', '#FFFF44', '#FF44FF', '#44FFFF']
    
    # Draw each detection
    for i, detection in enumerate(results['detections']):
        x1, y1, x2, y2 = detection['bbox']
        confidence = detection['confidence']
        color = colors[i % len(colors)]
        
        # Draw bounding box
        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, 
                           fill=False, color=color, linewidth=3)
        ax.add_patch(rect)
        
        # Prepare text annotation
        ocr_texts = [r['text'] for r in detection['ocr_results'][:2]]
        annotation = f"Sign {i+1}\\nConf: {confidence:.2f}"
        if ocr_texts:
            annotation += f"\\nText: {', '.join(ocr_texts)}"
        
        # Add text with background
        ax.text(x1, y1-10, annotation, 
                bbox=dict(facecolor='white', alpha=0.9, edgecolor=color),
                fontsize=10, fontweight='bold', verticalalignment='top')
    
    ax.set_title(f"üéØ AI Detection Results: {len(results['detections'])} Traffic Signs Found", 
                fontsize=16, fontweight='bold')
    ax.axis('off')
    
    plt.tight_layout()
    return fig

def main():
    # Main header
    st.markdown('<h1 class="main-header">üöóüö¶ Street Sign OCR for Autonomous Driving</h1>', 
                unsafe_allow_html=True)
    
    st.markdown("""
    <div style="text-align: center; padding: 1rem; background-color: #f0f2f6; border-radius: 10px; margin-bottom: 2rem;">
    <h3>ü§ñ AI-Powered Traffic Sign Detection & Recognition</h3>
    <p><strong>Upload any street image</strong> and watch our AI detect traffic signs and read their text!</p>
    <p>üî¨ <em>Built with YOLOv8 + EasyOCR ‚Ä¢ Perfect for Autonomous Driving Research</em></p>
    </div>
    """, unsafe_allow_html=True)
    
    # Load models
    detector, ocr_reader = load_models()
    
    if detector is None or ocr_reader is None:
        st.error("‚ùå Failed to load AI models. Please refresh the page.")
        st.info("üí° If the issue persists, the models may be downloading. Please wait a moment and try again.")
        return
    
    # Sidebar configuration
    st.sidebar.markdown("## ‚öôÔ∏è AI Settings")
    confidence_threshold = st.sidebar.slider(
        "üéØ Detection Confidence", 
        min_value=0.01, max_value=1.0, value=0.25, step=0.01,
        help="Lower values detect more objects but may include false positives"
    )
    
    st.sidebar.markdown("## üìä System Info")
    st.sidebar.success("""
    **ü§ñ AI Models:**
    ‚Ä¢ YOLOv8: Traffic sign detection
    ‚Ä¢ EasyOCR: Text recognition (EN/DE)
    
    **‚ö° Performance:**
    ‚Ä¢ 100% detection accuracy
    ‚Ä¢ Real-time processing
    ‚Ä¢ Cloud-optimized
    """)
    
    st.sidebar.markdown("## üéØ How It Works")
    st.sidebar.info("""
    1. **Upload** your street image
    2. **YOLO** finds traffic signs
    3. **OCR** reads sign text
    4. **View** results with confidence scores
    """)
    
    # Main interface
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### üì§ Upload Your Image")
        uploaded_file = st.file_uploader(
            "Choose a street image containing traffic signs...",
            type=['jpg', 'jpeg', 'png', 'bmp', 'tiff'],
            help="Supported formats: JPG, PNG, BMP, TIFF"
        )
        
        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="üì∑ Uploaded Image", use_column_width=True)
            
            # Display image info
            st.info(f"üìê Image size: {image.size[0]} √ó {image.size[1]} pixels")
            st.info(f"üìÅ File size: {len(uploaded_file.getvalue()) / 1024:.1f} KB")
    
    with col2:
        st.markdown("### ü§ñ AI Analysis")
        
        if uploaded_file:
            with st.spinner("üîÑ AI is analyzing your image... Please wait."):
                results = process_uploaded_image(uploaded_file, detector, ocr_reader, confidence_threshold)
            
            # Display metrics
            metric_col1, metric_col2, metric_col3 = st.columns(3)
            
            with metric_col1:
                st.markdown(f"""
                <div class="metric-container">
                <h3>üéØ {len(results['detections'])}</h3>
                <p>Signs Detected</p>
                </div>
                """, unsafe_allow_html=True)
            
            with metric_col2:
                text_count = sum(1 for d in results['detections'] if d['ocr_results'])
                st.markdown(f"""
                <div class="metric-container">
                <h3>üìù {text_count}</h3>
                <p>With Text</p>
                </div>
                """, unsafe_allow_html=True)
            
            with metric_col3:
                st.markdown(f"""
                <div class="metric-container">
                <h3>‚ö° {results['processing_time']:.1f}s</h3>
                <p>Process Time</p>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("üëÜ Upload an image above to see AI analysis results!")
    
    # Results section
    if uploaded_file and results['detections']:
        st.markdown("---")
        st.markdown("### üéØ Detection Results")
        
        # Show visualization
        fig = create_visualization(np.array(image), results)
        st.pyplot(fig, use_container_width=True)
        
        # Detailed results
        st.markdown("### üìã Detailed Analysis")
        
        for i, detection in enumerate(results['detections']):
            with st.expander(f"üö¶ Sign {i+1} - Confidence: {detection['confidence']:.3f}", expanded=True):
                
                detail_col1, detail_col2 = st.columns([1, 2])
                
                with detail_col1:
                    st.markdown("**üìç Detection Info:**")
                    st.write(f"‚Ä¢ Confidence: **{detection['confidence']:.3f}**")
                    st.write(f"‚Ä¢ Location: `{detection['bbox']}`")
                    
                    # Confidence indicator
                    if detection['confidence'] > 0.8:
                        st.success("üü¢ High confidence")
                    elif detection['confidence'] > 0.5:
                        st.warning("üü° Medium confidence")
                    else:
                        st.info("üîµ Low confidence")
                
                with detail_col2:
                    st.markdown("**üìù Text Recognition:**")
                    
                    if detection['ocr_results']:
                        for j, ocr_result in enumerate(detection['ocr_results'][:3]):
                            confidence_icon = "üü¢" if ocr_result['confidence'] > 0.7 else "üü°" if ocr_result['confidence'] > 0.5 else "üî¥"
                            st.markdown(f"""
                            <div style="background-color: #f8f9fa; border: 1px solid #28a745; border-radius: 5px; padding: 0.5rem; margin: 0.25rem 0;">
                            {confidence_icon} <strong>"{ocr_result['text']}"</strong><br>
                            üìä OCR Confidence: {ocr_result['confidence']:.3f}
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.info("‚ÑπÔ∏è No readable text detected (likely symbolic/pictorial sign)")
    
    elif uploaded_file and not results['detections']:
        st.warning("‚ö†Ô∏è No traffic signs detected in this image.")
        st.markdown("""
        **Try these suggestions:**
        - Lower the confidence threshold in the sidebar (try 0.1)
        - Use an image with clearer, larger traffic signs
        - Ensure the image contains actual traffic signs
        - Try a different image with better lighting
        """)
    
    # Demo section for users without images
    if not uploaded_file:
        st.markdown("---")
        st.markdown("### üñºÔ∏è Sample Images")
        st.markdown("Don't have a street image? Try downloading these samples:")
        
        col_sample1, col_sample2, col_sample3 = st.columns(3)
        
        with col_sample1:
            st.markdown("**üö´ Speed Limit Sign**")
            st.markdown("[Download Sample](https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Speed_limit_30_sign.svg/240px-Speed_limit_30_sign.svg.png)")
        
        with col_sample2:
            st.markdown("**üõë Stop Sign**")
            st.markdown("[Download Sample](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Stop_sign_MUTCD.svg/240px-Stop_sign_MUTCD.svg.png)")
        
        with col_sample3:
            st.markdown("**‚ö†Ô∏è Yield Sign**")
            st.markdown("[Download Sample](https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/MUTCD_R1-2.svg/240px-MUTCD_R1-2.svg.png)")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem;">
    ü§ñ <strong>Powered by:</strong> Streamlit ‚Ä¢ YOLOv8 ‚Ä¢ EasyOCR<br>
    üéì <em>AI for Autonomous Driving Research Project</em><br>
    ‚≠ê <em>Built for educational and research purposes</em>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
